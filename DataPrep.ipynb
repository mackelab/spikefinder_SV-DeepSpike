{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:12.288281Z",
     "start_time": "2017-09-20T10:01:10.062063Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"engine/\")\n",
    "sys.path.append(\"funcs/\")\n",
    "\n",
    "from theano import config\n",
    "import numpy as np\n",
    "import pickle \n",
    "import copy\n",
    "import time \n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "\n",
    "%matplotlib inline\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpreprocessed data available at:\n",
    "https://www.dropbox.com/s/ugmet5eky8g0l5n/datasets%201-5%20nopreprocessing.zip?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:12.369801Z",
     "start_time": "2017-09-20T10:01:12.291029Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def get_hz(spikes,hz):\n",
    "    return sum(spikes)/(len(spikes)/hz)\n",
    "\n",
    "def percentile_detrend(trace,wwidth,percentile):\n",
    "    \n",
    "    trend = np.zeros_like(trace)\n",
    "    for t in range(len(trace)):\n",
    "        window = np.max([0,t-wwidth/2]).astype(int),np.min([len(trace),t+wwidth/2]).astype(int)\n",
    "        trend[t] = np.percentile(trace[window[0]:window[1]],5)\n",
    "    return trend\n",
    "\n",
    "def percentile_resize(trace,botperc,topperc):\n",
    "\n",
    "    bot = np.percentile(trace, botperc)\n",
    "    top = np.percentile(trace, topperc)\n",
    "\n",
    "    return (trace - bot) / (top - bot)\n",
    "\n",
    "def dFoF(trace,wwidth,percentile):\n",
    "    \n",
    "    restrace = np.zeros_like(trace)\n",
    "    for t in range(len(trace)):\n",
    "        window = np.max([0,t-wwidth/2]).astype(int),np.min([len(trace),t+wwidth/2]).astype(int)\n",
    "        trend = np.percentile(trace[window[0]:window[1]],percentile)\n",
    "        restrace[t] = (trace[t]-trend)/trend\n",
    "    return restrace\n",
    "\n",
    "def list_mean(list):\n",
    "    totsum = 0\n",
    "    totlen = 0\n",
    "    for t in list:\n",
    "        totsum += np.sum(t)\n",
    "        totlen += len(t)\n",
    "    return totsum/totlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAI-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 OGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:12.624685Z",
     "start_time": "2017-09-20T10:01:12.371707Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traces = pd.read_csv('1.train.calcium.nopreprocessing.csv')\n",
    "spiketimes = pd.read_csv('1.train.spike.nopreprocessing.csv')\n",
    "\n",
    "n_cells = len(traces.columns)\n",
    "\n",
    "traces_raw = [[] for x in range(n_cells)]\n",
    "spikes_raw = [[] for x in range(n_cells)]\n",
    "traces_prep = [[] for x in range(n_cells)]\n",
    "\n",
    "fps = []\n",
    "spikefps = 300\n",
    "\n",
    "for i in range(0,n_cells):\n",
    "    fps.append(traces[str(i+1)][0])\n",
    "    tra = traces[str(i+1)][1:]\n",
    "    sp = spiketimes[str(i+1)][1:]\n",
    "    tra = np.array(tra[~np.isnan(tra)])\n",
    "    sp = np.array(sp[~np.isnan(sp)])\n",
    "    traces_raw[i].append(tra)\n",
    "    \n",
    "    T = len(tra)*1000/fps[-1]\n",
    "    bins = np.arange(0,T,1000/spikefps)\n",
    "    spikes_raw[i].append(np.histogram(sp, bins)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:12.676970Z",
     "start_time": "2017-09-20T10:01:12.626568Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "traces = pd.read_csv('1.test.calcium.nopreprocessing.csv')\n",
    "\n",
    "n_cells = len(traces.columns)\n",
    "\n",
    "traces_testset = [[] for x in range(n_cells)]\n",
    "traces_testset_prep = [[] for x in range(n_cells)]\n",
    "\n",
    "fps_testset = []\n",
    "\n",
    "for i in range(0,n_cells):\n",
    "\n",
    "    fps_testset.append(traces[str(i+1)][0])\n",
    "    tra = traces[str(i+1)][1:]\n",
    "    tra = np.array(tra[~np.isnan(tra)])\n",
    "    traces_testset[i].append(tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:12.703926Z",
     "start_time": "2017-09-20T10:01:12.678487Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(traces_raw)):\n",
    "    for j in range(len(traces_raw[i])):        \n",
    "        \n",
    "        trace = percentile_resize(traces_raw[i][j],5,60)\n",
    "        traces_prep[i].append(trace)\n",
    "\n",
    "for i in range(len(traces_testset)):\n",
    "    for j in range(len(traces_testset[i])):        \n",
    "        \n",
    "        trace = percentile_resize(traces_testset[i][j],5,60)\n",
    "        traces_testset_prep[i].append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:13.151395Z",
     "start_time": "2017-09-20T10:01:12.705437Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(traces_prep)):\n",
    "    mean = list_mean(traces_prep[i])\n",
    "    for j in range(len(traces_prep[i])):\n",
    "        traces_prep[i][j] = np.array(traces_prep[i][j] - mean, dtype = config.floatX)\n",
    "        \n",
    "for i in range(len(traces_testset_prep)):\n",
    "    mean = list_mean(traces_testset_prep[i])\n",
    "    for j in range(len(traces_testset_prep[i])):\n",
    "        traces_testset_prep[i][j] = np.array(traces_testset_prep[i][j] - mean, dtype = config.floatX)\n",
    "\n",
    "spikes_train = copy.deepcopy(spikes_raw)\n",
    "traces_train = copy.deepcopy(traces_prep)\n",
    "      \n",
    "data_dict = {'traces': traces_train, 'spikes': spikes_train, 'traces_test':traces_prep, 'spikes_test':spikes_raw, 'traces_testset':traces_testset_prep, 'fps' : fps, 'fps_testset' : fps_testset, 'spike_fps': spikefps}\n",
    "\n",
    "with open('real_cai3np_ogb1.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OGB 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:13.506428Z",
     "start_time": "2017-09-20T10:01:13.154836Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "traces = pd.read_csv('2.train.calcium.nopreprocessing.csv')\n",
    "spiketimes = pd.read_csv('2.train.spike.nopreprocessing.csv')\n",
    "\n",
    "n_cells = len(traces.columns)\n",
    "\n",
    "traces_raw = [[] for x in range(n_cells)]\n",
    "spikes_raw = [[] for x in range(n_cells)]\n",
    "traces_prep = [[] for x in range(n_cells)]\n",
    "\n",
    "fps = []\n",
    "spikefps = 300\n",
    "\n",
    "for i in range(0,n_cells):\n",
    "    fps.append(traces[str(i+1)][0])\n",
    "    tra = traces[str(i+1)][1:]\n",
    "    sp = spiketimes[str(i+1)][1:]\n",
    "    tra = np.array(tra[~np.isnan(tra)])\n",
    "    sp = np.array(sp[~np.isnan(sp)])\n",
    "    traces_raw[i].append(tra)\n",
    "    \n",
    "    T = len(tra)*1000/fps[-1]\n",
    "    bins = np.arange(0,T,1000/spikefps)\n",
    "    spikes_raw[i].append(np.histogram(sp, bins)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:13.545327Z",
     "start_time": "2017-09-20T10:01:13.508379Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "traces = pd.read_csv('2.test.calcium.nopreprocessing.csv')\n",
    "\n",
    "n_cells = len(traces.columns)\n",
    "\n",
    "traces_testset = [[] for x in range(n_cells)]\n",
    "traces_testset_prep = [[] for x in range(n_cells)]\n",
    "\n",
    "fps_testset = []\n",
    "\n",
    "for i in range(0,n_cells):\n",
    "    fps_testset.append(traces[str(i+1)][0])\n",
    "    tra = traces[str(i+1)][1:]\n",
    "    tra = np.array(tra[~np.isnan(tra)])\n",
    "    traces_testset[i].append(tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:13.573449Z",
     "start_time": "2017-09-20T10:01:13.546973Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(traces_raw)):\n",
    "    for j in range(len(traces_raw[i])):        \n",
    "        \n",
    "        trace = percentile_resize(traces_raw[i][j],5,60)\n",
    "        traces_prep[i].append(trace)\n",
    "        \n",
    "for i in range(len(traces_testset)):\n",
    "    for j in range(len(traces_testset[i])):        \n",
    "        \n",
    "        trace = percentile_resize(traces_testset[i][j],5,60)\n",
    "        traces_testset_prep[i].append(trace)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:13.637169Z",
     "start_time": "2017-09-20T10:01:13.575767Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "spikes_train = copy.deepcopy(spikes_raw)\n",
    "traces_train = copy.deepcopy(traces_prep)\n",
    "\n",
    "traces_train[7][0] = traces_train[7][0][300:]\n",
    "spikes_train[7][0] = spikes_train[7][0][int(300*spikefps/fps[7]):]\n",
    "\n",
    "traces_train[8][0] = traces_train[8][0][:3100]\n",
    "spikes_train[8][0] = spikes_train[8][0][:int(3100*spikefps/fps[8])]\n",
    "\n",
    "traces_train[12][0] = traces_train[12][0][800:]\n",
    "spikes_train[12][0] = spikes_train[12][0][int(800*spikefps/fps[12]):]\n",
    "\n",
    "traces_train[13][0] = traces_train[13][0][200:]\n",
    "spikes_train[13][0] = spikes_train[13][0][int(200*spikefps/fps[13]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:14.209850Z",
     "start_time": "2017-09-20T10:01:13.641322Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(traces_train)):\n",
    "    mean = list_mean(traces_train[i])\n",
    "    for j in range(len(traces_train[i])):\n",
    "        traces_train[i][j] = np.array(traces_train[i][j] - mean, dtype = config.floatX)\n",
    "        traces_prep[i][j] = np.array(traces_prep[i][j] - mean, dtype = config.floatX)\n",
    "        \n",
    "for i in range(len(traces_testset_prep)):\n",
    "    mean = list_mean(traces_testset_prep[i])\n",
    "    for j in range(len(traces_testset_prep[i])):\n",
    "        traces_testset_prep[i][j] = np.array(traces_testset_prep[i][j] - mean, dtype = config.floatX)\n",
    "        \n",
    "data_dict = {'traces': traces_train, 'spikes': spikes_train, 'traces_test':traces_prep, 'spikes_test':spikes_raw, 'traces_testset':traces_testset_prep, 'fps' : fps, 'fps_testset' : fps_testset, 'spike_fps': spikefps}\n",
    "\n",
    "with open('real_cai3np_ogb2.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## OGB 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:14.324791Z",
     "start_time": "2017-09-20T10:01:14.213560Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "traces = pd.read_csv('4.train.calcium.nopreprocessing.csv')\n",
    "spiketimes = pd.read_csv('4.train.spike.nopreprocessing.csv')\n",
    "\n",
    "n_cells = len(traces.columns)\n",
    "\n",
    "traces_raw = [[] for x in range(n_cells)]\n",
    "spikes_raw = [[] for x in range(n_cells)]\n",
    "traces_prep = [[] for x in range(n_cells)]\n",
    "\n",
    "fps = []\n",
    "spikefps = 300\n",
    "\n",
    "for i in range(0,n_cells):\n",
    "    fps.append(traces[str(i+1)][0])\n",
    "    tra = traces[str(i+1)][1:]\n",
    "    sp = spiketimes[str(i+1)][1:]\n",
    "    tra = np.array(tra[~np.isnan(tra)])\n",
    "    sp = np.array(sp[~np.isnan(sp)])\n",
    "    traces_raw[i].append(tra)\n",
    "    \n",
    "    T = len(tra)*1000/fps[-1]\n",
    "    bins = np.arange(0,T,1000/spikefps)\n",
    "    spikes_raw[i].append(np.histogram(sp, bins)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:14.352332Z",
     "start_time": "2017-09-20T10:01:14.327254Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "traces = pd.read_csv('4.test.calcium.nopreprocessing.csv')\n",
    "\n",
    "n_cells = len(traces.columns)\n",
    "\n",
    "traces_testset = [[] for x in range(n_cells)]\n",
    "traces_testset_prep = [[] for x in range(n_cells)]\n",
    "\n",
    "fps_testset = []\n",
    "\n",
    "for i in range(0,n_cells):\n",
    "    fps_testset.append(traces[str(i+1)][0])\n",
    "    tra = traces[str(i+1)][1:]\n",
    "    tra = np.array(tra[~np.isnan(tra)])\n",
    "    traces_testset[i].append(tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:14.375972Z",
     "start_time": "2017-09-20T10:01:14.354553Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(traces_raw)):\n",
    "    for j in range(len(traces_raw[i])):        \n",
    "        \n",
    "        trace = percentile_resize(traces_raw[i][j],5,60)\n",
    "        traces_prep[i].append(trace)\n",
    "\n",
    "for i in range(len(traces_testset)):\n",
    "    for j in range(len(traces_testset[i])):        \n",
    "        \n",
    "        trace = percentile_resize(traces_testset[i][j],5,60)\n",
    "        traces_testset_prep[i].append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:14.544545Z",
     "start_time": "2017-09-20T10:01:14.378786Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "spikes_train = copy.deepcopy(spikes_raw)\n",
    "traces_train = copy.deepcopy(traces_prep)\n",
    "\n",
    "for i in range(len(traces_train)):\n",
    "    mean = list_mean(traces_train[i])\n",
    "    for j in range(len(traces_train[i])):\n",
    "        traces_train[i][j] = np.array(traces_train[i][j] - mean, dtype = config.floatX)\n",
    "        traces_prep[i][j] = np.array(traces_prep[i][j] - mean, dtype = config.floatX)\n",
    "        \n",
    "for i in range(len(traces_testset_prep)):\n",
    "    mean = list_mean(traces_testset_prep[i])\n",
    "    for j in range(len(traces_testset_prep[i])):\n",
    "        traces_testset_prep[i][j] = np.array(traces_testset_prep[i][j] - mean, dtype = config.floatX)\n",
    "        \n",
    "data_dict = {'traces': traces_train, 'spikes': spikes_train, 'traces_test':traces_prep, 'spikes_test':spikes_raw, 'traces_testset':traces_testset_prep, 'fps' : fps, 'fps_testset' : fps_testset, 'spike_fps': spikefps}\n",
    "\n",
    "with open('real_cai3np_ogb4.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCamp6s 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:14.794350Z",
     "start_time": "2017-09-20T10:01:14.548097Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "traces = pd.read_csv('3.train.calcium.nopreprocessing.csv')\n",
    "spiketimes = pd.read_csv('3.train.spike.nopreprocessing.csv')\n",
    "\n",
    "n_cells = len(traces.columns)\n",
    "\n",
    "traces_raw = [[] for x in range(n_cells)]\n",
    "spikes_raw = [[] for x in range(n_cells)]\n",
    "traces_prep = [[] for x in range(n_cells)]\n",
    "\n",
    "\n",
    "fps = []\n",
    "spikefps = 300\n",
    "\n",
    "for i in range(0,n_cells):\n",
    "    fps.append(traces[str(i+1)][0])\n",
    "    tra = traces[str(i+1)][1:]\n",
    "    sp = spiketimes[str(i+1)][1:]\n",
    "    tra = np.array(tra[~np.isnan(tra)])\n",
    "    sp = np.array(sp[~np.isnan(sp)])\n",
    "    traces_raw[i].append(tra)\n",
    "    \n",
    "    T = len(tra)*1000/fps[-1]\n",
    "    bins = np.arange(0,T,1000/spikefps)\n",
    "    spikes_raw[i].append(np.histogram(sp, bins)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:01:14.865939Z",
     "start_time": "2017-09-20T10:01:14.796452Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "traces = pd.read_csv('3.test.calcium.nopreprocessing.csv')\n",
    "\n",
    "n_cells = len(traces.columns)\n",
    "\n",
    "traces_testset = [[] for x in range(n_cells)]\n",
    "traces_testset_prep = [[] for x in range(n_cells)]\n",
    "\n",
    "fps_testset = []\n",
    "\n",
    "for i in range(0,n_cells):\n",
    "\n",
    "    fps_testset.append(traces[str(i+1)][0])\n",
    "    tra = traces[str(i+1)][1:]\n",
    "    tra = np.array(tra[~np.isnan(tra)])\n",
    "    traces_testset[i].append(tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:02:26.175293Z",
     "start_time": "2017-09-20T10:01:14.867957Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(traces_raw)):\n",
    "    for j in range(len(traces_raw[i])):        \n",
    "        \n",
    "        trace = dFoF(traces_raw[i][j],10000,5)\n",
    "        traces_prep[i].append(trace)\n",
    "        \n",
    "\n",
    "for i in range(len(traces_testset)):\n",
    "    for j in range(len(traces_testset[i])):        \n",
    "        \n",
    "        trace = dFoF(traces_testset[i][j],10000,5)\n",
    "        traces_testset_prep[i].append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:02:26.215350Z",
     "start_time": "2017-09-20T10:02:26.177310Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "spikes_train = copy.deepcopy(spikes_raw)\n",
    "traces_train = copy.deepcopy(traces_prep)\n",
    "\n",
    "traces_train[4][0] = traces_train[4][0][:12500]\n",
    "spikes_train[4][0] = spikes_train[4][0][:int(12500*spikefps/fps[8])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:02:26.651780Z",
     "start_time": "2017-09-20T10:02:26.217188Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(traces_train)):\n",
    "    mean = list_mean(traces_train[i])\n",
    "    for j in range(len(traces_train[i])):\n",
    "        traces_train[i][j] = np.array(traces_train[i][j] - mean, dtype = config.floatX)\n",
    "        traces_prep[i][j] = np.array(traces_prep[i][j] - mean, dtype = config.floatX)\n",
    "        \n",
    "del traces_train[5][0]\n",
    "del spikes_train[5][0]        \n",
    "        \n",
    "for i in range(len(traces_testset_prep)):\n",
    "    mean = list_mean(traces_testset_prep[i])\n",
    "    for j in range(len(traces_testset_prep[i])):\n",
    "        traces_testset_prep[i][j] = np.array(traces_testset_prep[i][j] - mean, dtype = config.floatX)\n",
    "        \n",
    "data_dict = {'traces': traces_train, 'spikes': spikes_train, 'traces_test':traces_prep, 'spikes_test':spikes_raw, 'traces_testset':traces_testset_prep, 'fps' : fps, 'fps_testset' : fps_testset, 'spike_fps': spikefps}\n",
    "\n",
    "with open('real_cai3np_gc3.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCamp6s 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:02:26.877080Z",
     "start_time": "2017-09-20T10:02:26.655518Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "traces = pd.read_csv('5.train.calcium.nopreprocessing.csv')\n",
    "spiketimes = pd.read_csv('5.train.spike.nopreprocessing.csv')\n",
    "\n",
    "n_cells = len(traces.columns)\n",
    "\n",
    "traces_raw = [[] for x in range(n_cells)]\n",
    "spikes_raw = [[] for x in range(n_cells)]\n",
    "traces_prep = [[] for x in range(n_cells)]\n",
    "\n",
    "\n",
    "fps = []\n",
    "spikefps = 300\n",
    "\n",
    "for i in range(0,n_cells):\n",
    "    fps.append(traces[str(i+1)][0])\n",
    "    tra = traces[str(i+1)][1:]\n",
    "    sp = spiketimes[str(i+1)][1:]\n",
    "    tra = np.array(tra[~np.isnan(tra)])\n",
    "    sp = np.array(sp[~np.isnan(sp)])\n",
    "    traces_raw[i].append(tra)\n",
    "    \n",
    "    T = len(tra)*1000/fps[-1]\n",
    "    bins = np.arange(0,T,1000/spikefps)\n",
    "    spikes_raw[i].append(np.histogram(sp, bins)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:02:26.942572Z",
     "start_time": "2017-09-20T10:02:26.880559Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "traces = pd.read_csv('5.test.calcium.nopreprocessing.csv')\n",
    "\n",
    "n_cells = len(traces.columns)\n",
    "\n",
    "traces_testset = [[] for x in range(n_cells)]\n",
    "traces_testset_prep = [[] for x in range(n_cells)]\n",
    "\n",
    "fps_testset = []\n",
    "\n",
    "for i in range(0,n_cells):\n",
    "\n",
    "    fps_testset.append(traces[str(i+1)][0])\n",
    "    tra = traces[str(i+1)][1:]\n",
    "    tra = np.array(tra[~np.isnan(tra)])\n",
    "    traces_testset[i].append(tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:02:45.394448Z",
     "start_time": "2017-09-20T10:02:26.945254Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(traces_raw)):\n",
    "    for j in range(len(traces_raw[i])):        \n",
    "        \n",
    "        trace = dFoF(traces_raw[i][j],10000,5)\n",
    "        traces_prep[i].append(trace)\n",
    "\n",
    "\n",
    "for i in range(len(traces_testset)):\n",
    "    for j in range(len(traces_testset[i])):        \n",
    "        \n",
    "        trace = dFoF(traces_testset[i][j],10000,5)\n",
    "        traces_testset_prep[i].append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:02:45.400521Z",
     "start_time": "2017-09-20T10:02:45.395945Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "spikes_train = copy.deepcopy(spikes_raw)\n",
    "traces_train = copy.deepcopy(traces_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T10:02:45.545245Z",
     "start_time": "2017-09-20T10:02:45.402146Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(traces_train)):\n",
    "    mean = list_mean(traces_train[i])\n",
    "    for j in range(len(traces_train[i])):\n",
    "        traces_train[i][j] = np.array(traces_train[i][j] - mean, dtype = config.floatX)\n",
    "        traces_prep[i][j] = np.array(traces_prep[i][j] - mean, dtype = config.floatX)     \n",
    "        \n",
    "for i in range(len(traces_testset_prep)):\n",
    "    mean = list_mean(traces_testset_prep[i])\n",
    "    for j in range(len(traces_testset_prep[i])):\n",
    "        traces_testset_prep[i][j] = np.array(traces_testset_prep[i][j] - mean, dtype = config.floatX)\n",
    "        \n",
    "data_dict = {'traces': traces_train, 'spikes': spikes_train, 'traces_test':traces_prep, 'spikes_test':spikes_raw, 'traces_testset':traces_testset_prep, 'fps' : fps,'fps_testset' : fps_testset, 'spike_fps': spikefps}\n",
    "\n",
    "with open('real_cai3np_gc5.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
